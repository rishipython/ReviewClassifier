{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReviewClassifier.ipynb",
      "provenance": [],
      "mount_file_id": "1UiX_2CyzJCDAqSJztulqZc4_D8kZLdmc",
      "authorship_tag": "ABX9TyNrkuKrV+hzbySToE4V5avY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishipython/ReviewClassifier/blob/main/ReviewClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNRNJNX4x9q-"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from random import randint"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlXAD37K7W0l"
      },
      "source": [
        "dir = f\"{os.sep}content{os.sep}drive{os.sep}My Drive{os.sep}ReviewClassifier{os.sep}\""
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apNQ-Sa3yCI5",
        "outputId": "2bff78f6-5d30-4c16-a7ff-4e784c19f267"
      },
      "source": [
        "# Data\r\n",
        "data = keras.datasets.imdb\r\n",
        "# Only uses 88000 most used words\r\n",
        "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=88000)\r\n",
        "word_index = data.get_word_index()\r\n",
        "word_index = {k:(v+3) for k, v in word_index.items()}\r\n",
        "word_index[\"<PAD>\"] = 0\r\n",
        "word_index[\"<START>\"] = 1\r\n",
        "word_index[\"<UNK>\"] = 2\r\n",
        "word_index[\"<UNUSED>\"] = 3\r\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GpmMTNLyHFf"
      },
      "source": [
        "# Sets data to same length (250) (adds padding)\r\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\r\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CR1SkS97yWf"
      },
      "source": [
        "np.save(dir + 'train_data.npy', train_data)\r\n",
        "np.save(dir + 'test_data.npy', test_data)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxQgHqK6yR6P"
      },
      "source": [
        "# Function for decoding data into human readable words\r\n",
        "def decode_review(text):\r\n",
        "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text]) # Note: get(i, \"?\") means to try to get word for i, but if not,\r\n",
        "    # put ?."
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ1oRKy9xjvu",
        "outputId": "dbee1ab6-5804-4871-9e6c-fa520830d06e"
      },
      "source": [
        "# Model\r\n",
        "model = keras.Sequential([\r\n",
        "    # Embedding layer finds word vectors for each word we pass it\r\n",
        "    # In our embedding layer, our word vectors are 16th dimensional\r\n",
        "    # 10000 is the number of word vectors\r\n",
        "    # Words will have similar values if they are similar, and very different values if they are very different\r\n",
        "    keras.layers.Embedding(88000, 16),\r\n",
        "    # Puts data into lower dimension\r\n",
        "    keras.layers.GlobalAveragePooling1D(),\r\n",
        "    keras.layers.Dense(50, activation=\"relu\"),\r\n",
        "    keras.layers.Dropout(0.2),\r\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\r\n",
        "])\r\n",
        "\r\n",
        "# Model summary\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# Compiles model\r\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "# Splits train data into training and cv sets\r\n",
        "x_val = train_data[:10000]\r\n",
        "x_train = train_data[10000:]\r\n",
        "y_val = train_labels[:10000]\r\n",
        "y_train = train_labels[10000:]\r\n",
        "\r\n",
        "# Fits model\r\n",
        "# Note: batch size is how many movie reviews we're doing at once\r\n",
        "fitModel = model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1)\r\n",
        "\r\n",
        "# Saves model\r\n",
        "model.save(dir + \"model\")"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, None, 16)          1408000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_7 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 50)                850       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 1,408,901\n",
            "Trainable params: 1,408,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "30/30 [==============================] - 2s 36ms/step - loss: 0.6928 - accuracy: 0.5032 - val_loss: 0.6901 - val_accuracy: 0.5730\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.6877 - accuracy: 0.6656 - val_loss: 0.6793 - val_accuracy: 0.7097\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.6708 - accuracy: 0.7548 - val_loss: 0.6509 - val_accuracy: 0.7741\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.6326 - accuracy: 0.7946 - val_loss: 0.6020 - val_accuracy: 0.7919\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.5724 - accuracy: 0.8174 - val_loss: 0.5393 - val_accuracy: 0.8116\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.5005 - accuracy: 0.8365 - val_loss: 0.4767 - val_accuracy: 0.8293\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.4305 - accuracy: 0.8622 - val_loss: 0.4240 - val_accuracy: 0.8463\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.3658 - accuracy: 0.8897 - val_loss: 0.3837 - val_accuracy: 0.8588\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.3177 - accuracy: 0.9005 - val_loss: 0.3542 - val_accuracy: 0.8670\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.2777 - accuracy: 0.9131 - val_loss: 0.3323 - val_accuracy: 0.8729\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.2451 - accuracy: 0.9255 - val_loss: 0.3165 - val_accuracy: 0.8767\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.2183 - accuracy: 0.9335 - val_loss: 0.3062 - val_accuracy: 0.8808\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.1957 - accuracy: 0.9396 - val_loss: 0.2951 - val_accuracy: 0.8830\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.1769 - accuracy: 0.9471 - val_loss: 0.2888 - val_accuracy: 0.8854\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1555 - accuracy: 0.9588 - val_loss: 0.2836 - val_accuracy: 0.8870\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1432 - accuracy: 0.9610 - val_loss: 0.2804 - val_accuracy: 0.8875\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.1281 - accuracy: 0.9693 - val_loss: 0.2779 - val_accuracy: 0.8880\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.1152 - accuracy: 0.9707 - val_loss: 0.2771 - val_accuracy: 0.8876\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.1093 - accuracy: 0.9723 - val_loss: 0.2769 - val_accuracy: 0.8887\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0962 - accuracy: 0.9782 - val_loss: 0.2766 - val_accuracy: 0.8890\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0842 - accuracy: 0.9833 - val_loss: 0.2789 - val_accuracy: 0.8887\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0778 - accuracy: 0.9846 - val_loss: 0.2790 - val_accuracy: 0.8892\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0710 - accuracy: 0.9863 - val_loss: 0.2810 - val_accuracy: 0.8906\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0665 - accuracy: 0.9866 - val_loss: 0.2834 - val_accuracy: 0.8902\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0581 - accuracy: 0.9907 - val_loss: 0.2857 - val_accuracy: 0.8893\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0545 - accuracy: 0.9907 - val_loss: 0.2881 - val_accuracy: 0.8882\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0515 - accuracy: 0.9903 - val_loss: 0.2922 - val_accuracy: 0.8893\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0448 - accuracy: 0.9928 - val_loss: 0.2961 - val_accuracy: 0.8882\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0434 - accuracy: 0.9935 - val_loss: 0.2988 - val_accuracy: 0.8889\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0407 - accuracy: 0.9930 - val_loss: 0.3020 - val_accuracy: 0.8879\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0361 - accuracy: 0.9956 - val_loss: 0.3070 - val_accuracy: 0.8873\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0348 - accuracy: 0.9941 - val_loss: 0.3109 - val_accuracy: 0.8860\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0306 - accuracy: 0.9958 - val_loss: 0.3153 - val_accuracy: 0.8854\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0295 - accuracy: 0.9958 - val_loss: 0.3197 - val_accuracy: 0.8843\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0288 - accuracy: 0.9960 - val_loss: 0.3221 - val_accuracy: 0.8853\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0234 - accuracy: 0.9976 - val_loss: 0.3260 - val_accuracy: 0.8844\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0230 - accuracy: 0.9973 - val_loss: 0.3298 - val_accuracy: 0.8840\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0210 - accuracy: 0.9980 - val_loss: 0.3344 - val_accuracy: 0.8833\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.0201 - accuracy: 0.9984 - val_loss: 0.3399 - val_accuracy: 0.8821\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0186 - accuracy: 0.9978 - val_loss: 0.3426 - val_accuracy: 0.8848\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/ReviewClassifier/model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8tEZh1A5EhX",
        "outputId": "11e7b6dd-9786-4fc4-ab08-60dfff257292"
      },
      "source": [
        "# Results\r\n",
        "results = model.evaluate(test_data, test_labels)\r\n",
        "print(f\"Results: Loss: {results[0]}, Accuracy: {results[1]}\")"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3881 - accuracy: 0.8664\n",
            "Results: Loss: 0.38813045620918274, Accuracy: 0.8663600087165833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EJaN1aPyZNV"
      },
      "source": [
        "# Makes function review encode which encodes review\r\n",
        "def review_encode(s):\r\n",
        "    encoded = [1]\r\n",
        "    for word in s:\r\n",
        "        if word in word_index:\r\n",
        "            encoded.append(word_index[word.lower()])\r\n",
        "        else:\r\n",
        "            encoded.append(2)\r\n",
        "    return encoded"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Asu9UvD_0TLK"
      },
      "source": [
        "num_to_review = {0: 'Negative review', 1:'Positive review'}"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y935TXp1dZb"
      },
      "source": [
        "def round(num):\r\n",
        "  if num >= 0.5:\r\n",
        "    return 1\r\n",
        "  else:\r\n",
        "    return 0"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rltVMGRqybRx",
        "outputId": "4b7cd806-9e9d-4b58-babf-e1dd2ea55043"
      },
      "source": [
        "# Looks at random and prints review, prediction, and actual value\r\n",
        "i = randint(0, len(test_data)-1)\r\n",
        "print(f\"i: {i}\")\r\n",
        "test_review = test_data[i]\r\n",
        "predict = model.predict([test_review])\r\n",
        "print(\"Review: \", end='')\r\n",
        "print(decode_review(test_review))\r\n",
        "print(f\"Prediction: {num_to_review[round(predict[0][0])]}\")\r\n",
        "print(f\"Actual: {num_to_review[test_labels[i]]}\")"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i: 8821\n",
            "Review: <START> sebastian cabot is a rich jerk who wants to buy up all the land because there is oil though none of the locals are aware of the oil with the help of an evil gunfighter in black they kill and terrorize everyone when the son of a murdered man arrives he refuses to back down and stands up to these forces of darkness br br wow as i watched terror in a texas town i felt as if i'd seen this film many times before and would probably see something like it again that's because aside from a few novelties such as sterling hayden using a harpoon on the bad guy it has a plot that is too familiar once again we've got a rich guy who is trying to drive out all the farmers in order to gain control of all the land and to do so he's brought in hired guns to force people to sell or kill them been there done that in just too many films br br i love sterling hayden in films but just couldn't recommend this as anything other than a poor time passer <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Prediction: Negative review\n",
            "Actual: Negative review\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}